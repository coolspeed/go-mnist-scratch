# 성능 분석 및 최적화 전략

## 1. 배경
우리는 단일 이미지 추론(Batch Size = 1)에서 10ms 미만의 지연 시간(latency)을 달성하는 동시에, 학습(Batch Size = 64) 시에는 높은 처리량(throughput)을 유지하는 것을 목표로 합니다.

## 2. 베이스라인 벤치마크 (최적화 전)

### 테스트 환경
- **OS**: Darwin (macOS)
- **Arch**: arm64 (Apple M2)
- **Matrix Operation**: `DotProduct` (784 features x 200 hidden neurons)

### 관찰 결과

#### A. 학습 시나리오 (Batch Size = 64)
- **순차 처리 (Sequential)**: 약 34.6 ms
- **병렬 처리 (Goroutines)**: 약 2.3 ms
- **결과**: **15배 속도 향상**. 대규모 행렬 연산에서 병렬화가 매우 효과적임.

#### B. 추론 시나리오 (Batch Size = 1)
- **병렬 처리 (Goroutines)**: 약 229 µs (평균)
- **순차 처리 (GOMAXPROCS=1 시뮬레이션)**: 약 220 µs (평균)
- **결과**: **성능 저하 발생**. 단일 행 계산 시에는 고루틴 생성 및 동기화(`sync.WaitGroup`) 오버헤드가 병렬화의 이점보다 큼.

## 3. 설계 결정: 적응형 병렬화 (Adaptive Parallelism)

두 시나리오 모두를 최적화하기 위해 `matrix.DotProduct` 함수에 **적응형 전략**을 구현합니다.

- **임계값 (Threshold)**: 행(row)의 개수에 대한 임계값을 설정합니다 (예: 4).
- **로직**:
    - `rows < Threshold`: 순차 실행 (동시성 오버헤드 회피).
    - `rows >= Threshold`: 병렬 실행 (멀티코어 활용).

### 기대 효과
- **추론 (Batch=1)**: 약 220 µs 이하로 복귀 (순차 처리 성능).
- **학습 (Batch=64)**: 약 2.3 ms 유지 (병렬 처리 성능).

## 4. 구현 후 검증 (Verification)

### 벤치마크 결과 (Batch=1)
적응형 임계값(`parallelThreshold = 4`) 구현 후, 단일 추론 벤치마크를 다시 실행했습니다.

- **결과**: 약 213 µs (평균)
- **성능 향상**: 
    - 병렬 처리 버전(229 µs) 대비: **약 7% 더 빠름**
    - 순차 처리 시뮬레이션(220 µs) 대비: **약 3% 더 빠름** (불필요한 고루틴 생성 로직 자체가 제거되었기 때문)

### 결론
적응형 병렬화 전략은 지연 시간(단일 추론)과 처리량(배치 학습) 두 마리 토끼를 모두 잡는 데 성공했습니다. 작은 행렬에 대해서는 고루틴 오버헤드를 제거함으로써, 해당 아키텍처에서 가능한 가장 빠른 추론 속도를 달성했습니다.